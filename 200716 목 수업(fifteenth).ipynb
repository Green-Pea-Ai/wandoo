{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lesson01  Lesson03  Lesson05  Lesson07\tLesson09  README.md\r\n",
      "Lesson02  Lesson04  Lesson06  Lesson08\tLICENSE\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/bitai/proj_my/Applied-Deep-Learning-with-Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c8ec22b3e787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo apt-get install pkg-config\n",
    "# pkg-config --modversion opencv\n",
    "# opencv에서 설치 안됐다고 뱉으면 다음으로 넘어가기\n",
    "# (나오면 삭제해야해서 오히려 골치아픔)\n",
    "\n",
    "# sudo apt-get install build-essential cmake\n",
    "# sudo apt-get install freeglut3 freeglut3-dev\n",
    "# sudo apt-get install glew-utils glee-dev\n",
    "# sudo apt-get install libglew-dev\n",
    "# sudo apt-get install libjpeg-dev libtiff5-dev libpng-dev\n",
    "# sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libxvidcore-dev libx264-dev libxine2-dev\n",
    "# sudo apt-get install libv4l-dev v4l-utils\n",
    "# sudo apt-get install libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev\n",
    "# sudo apt-get install libgtk2.0-dev\n",
    "# sudo apt-get install mesa-utils libgl1-mesa-dri libgtkgl2.0-dev libgtkglext1-dev\n",
    "# sudo apt-get install libatlas-base-dev gfortran libeigen3-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd ~\n",
    "# cd sw/\n",
    "# mkdir opencv\n",
    "# cd opencv\n",
    "# wget -O opencv.zip https://github.com/opencv/opencv/archive/4.2.0.zip\n",
    "# unzip opencv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/4.2.0.zip\n",
    "# unzip opencv_contrib.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd opencv-4.2.0/\n",
    "# mkdir build\n",
    "# cd build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아나콘다 환경 설정 잠시 정지시킴\n",
    "# sudo apt-get install python2.7-dev python3-dev python-numpy python3-numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/bitai/anaconda3/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아나콘다 경로를 잘 파악하고 있다면 문제 없음\n",
    "# cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=OFF -D WITH_IPP=OFF -D WITH_1394=OFF -D BUILD_WITH_DEBUG_INFO=OFF -D BUILD_DOCS=OFF -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=OFF -D WITH_QT=OFF -D WITH_GTK=ON -D WITH_OPENGL=ON -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-4.2.0/modules -D WITH_V4L=ON -D WITH_FFMPEG=ON -D WITH_XINE=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D OPENCV_GENERATE_PKGCONFIG=ON ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아나콘다상의 파이썬 경로를 파악하지 못한다면 아래 방식으로\n",
    "# cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=OFF -D WITH_IPP=OFF -D WITH_1394=OFF -D BUILD_WITH_DEBUG_INFO=OFF -D BUILD_DOCS=OFF -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=OFF -D WITH_QT=OFF -D WITH_GTK=ON -D WITH_OPENGL=ON -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-4.2.0/modules -D WITH_V4L=ON -D WITH_FFMPEG=ON -D WITH_XINE=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D OPENCV_GENERATE_PKGCONFIG=ON -D PYTHON3_INCLUDE_DIR=/home/bitai/anaconda3/include/python3.7m/ -D PYTHON3_NUMPY_INCLUDE_DIRS=/home/bitai/anaconda3/lib/python3.7/site-packages/numpy/core/include/ -D PYTHON3_PACKAGES_PATH=/home/bitai/anaconda3/lib/python3.7/site-packages -D PYTHON3_LIBRARY=/home/bitai/anaconda3/lib/libpython3.7m.so ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat /proc/cpuinfo | grep processor | wc -l\n",
    "# time make -j12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat /etc/ld.so.conf.d/*\n",
    "# sudo ldconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd ~/proj/\n",
    "# mkdir test\n",
    "# cd test\n",
    "# g++ -o facedetect /usr/local/share/opencv4/samples/cpp/facedetect.cpp $(pkg-config opencv4 --libs --cflags)\n",
    "# ./facedetect --cascade=\"/usr/local/share/opencv4/haarcascades/haarcascade_frontalface_alt.xml\" --nested-cascade=\"/usr/local/share/opencv4/haarcascades/haarcascade_eye_tree_eyeglasses.xml\" --scale=1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아나콘다 설정 다시 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# 위는 주피터에서 쓰는 코드고 터미널에서 이미 완료함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.0\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 5 9 3 1 5 0]\n",
      " [5 9 7 0 8 9 8]\n",
      " [7 4 8 6 1 7 3]\n",
      " [2 3 4 8 0 0 6]\n",
      " [8 7 3 2 5 1 0]\n",
      " [2 6 1 3 9 9 6]\n",
      " [9 2 3 0 7 0 8]]\n"
     ]
    }
   ],
   "source": [
    "img = np.random.randint(0, 10, (7, 7))\n",
    "\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "img_np = np.ones([7, 7])\n",
    "\n",
    "print(img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1]\n"
     ]
    }
   ],
   "source": [
    "kernel = np.array([-1, 0, 1])\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 넘파이 형식으로 이미지에는 못씀, 변환필요\n",
    "print(type(kernel))\n",
    "print(type(img_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "img_cv = cv2.resize(img_np, (7, 7))\n",
    "\n",
    "print(img_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1]\n",
      " [ 0]\n",
      " [ 1]]\n"
     ]
    }
   ],
   "source": [
    "kernel = cv2.resize(kernel, (1, 3))\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 넘피로 나오지만 이미지 연산에 쓸 수 있음\n",
    "print(type(img_cv))\n",
    "print(type(kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "conv_test = cv2.filter2D(img_cv, -1, kernel)\n",
    "\n",
    "print(conv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1]\n",
      " [ 0]\n",
      " [ 1]]\n"
     ]
    }
   ],
   "source": [
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(img_cv)\n",
    "\n",
    "# 가로는 0\n",
    "# 세로는 ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "img_cv[0][0] = 0\n",
    "img_cv[3][3] = 2\n",
    "img_cv[6][6] = 3\n",
    "\n",
    "# filter2D - Convolution이\n",
    "# 결국 라플라스 변환과 푸리에 변환에 관계를 가지고 있기 때문\n",
    "conv_test = cv2.filter2D(img_cv, -1, kernel)\n",
    "\n",
    "print(conv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo apt-get install ctags cscope\n",
    "\n",
    "# in, k(kernel)가 중요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 책 끝나고 아래 내용 다시 설명해주기로 함\n",
    "# 까먹으면 말해달라고 하심\n",
    "\n",
    "# 라플라스 변환 => 전달 함수를 얻기 위해 계산함\n",
    "# 라플라스 변환 - 미분 쉽게 계산하려고 배움?(거짓말)\n",
    "# 입력 대 출력비를 구하겠다.\n",
    "# 입력이 10, 출력이 7, 입출력비: 7/10\n",
    "# 입력이 y'' = y' + 3y + 2\n",
    "# 출력이 y' = 3e^3x => y = e^3x\n",
    "# 라플라스 변환 통해 입출력비를 계산할 수 있게 된다. \n",
    "# 미분 방정식으로도 구할 수 없는 출력비를 구할 때 라플라스를 쓴다.\n",
    "\n",
    "# 라플라스 역변환하면 시간의 함수가 얻어짐(원래값 x(t)?)\n",
    "# integral 0 ~ inf(무한) f(t)e^-st dt \n",
    "# 퀄컴 s-시프팅, 스마트폰에 이미 있음? \n",
    "\n",
    "# 1계 미분 방정식(RC 회로)\n",
    "# 라플라스 변환, 푸리에 변환 약식\n",
    "# Low Pass Filter(LPF 설계법) - 1D Convolution\n",
    "# 전달함수 -> 실제 값을 필터링 하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(\n",
    "    Conv2D(\n",
    "        32, (3, 3), \n",
    "        input_shape = (64, 64, 3), \n",
    "        activation = 'relu'\n",
    "    )\n",
    ")\n",
    "classifier.add(\n",
    "    Conv2D(\n",
    "        32, (3, 3), \n",
    "        activation = 'relu'\n",
    "    )\n",
    ")\n",
    "classifier.add(\n",
    "    Conv2D(\n",
    "        32, (3, 3), \n",
    "        activation = 'relu'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# MaxPool2D 2 by 2 행렬로 이동하면서 최대 풀링을 해준다? \n",
    "classifier.add(MaxPool2D(pool_size = (2, 2)))\n",
    "classifier.add(MaxPool2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 58, 58, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "=================================================================\n",
      "Total params: 19,392\n",
      "Trainable params: 19,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 컨볼루션 할 네트워크 확인\n",
    "# 텐서 연산을 사용하고 있다 / (None, 62, 62, 32) \n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크 모델 1 - 50%, 오판\n",
    "\n",
    "classifier.add(\n",
    "    Dense(128, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(128, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(128, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(128, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(1, activation = 'softmax')\n",
    ")\n",
    "\n",
    "classifier.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크 모델 2 - 50% 대\n",
    "\n",
    "classifier.add(\n",
    "    Dense(512, activation = 'tanh')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(300, activation = 'tanh')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(150, activation = 'tanh')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(75, activation = 'tanh')\n",
    ")\n",
    "\n",
    "classifier.add(\n",
    "    Dense(300, activation = 'tanh')\n",
    ")\n",
    "\n",
    "classifier.add(\n",
    "    Dense(1, activation = 'sigmoid')\n",
    ")\n",
    "\n",
    "classifier.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크 모델 3\n",
    "\n",
    "classifier.add(\n",
    "    Dense(128, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(128, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(128, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(128, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(64, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(32, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(16, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(1, activation = 'sigmoid')\n",
    ")\n",
    "\n",
    "classifier.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    # 0~255의 값을 0~1.0으로 수렴 시킨다? \n",
    "    rescale = 1.0 / 255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale = 1.0 / 255)\n",
    "# train_gen = ImageDataGenerator(rescale = 1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lesson01  Lesson03  Lesson05  Lesson07\tLesson09  README.md\r\n",
      "Lesson02  Lesson04  Lesson06  Lesson08\tLICENSE\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/bitai/proj_my/Applied-Deep-Learning-with-Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity13.ipynb  Datasets\t    Exercise20.ipynb  Exercise22.ipynb\r\n",
      "Activity14.ipynb  Exercise19.ipynb  Exercise21.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/bitai/proj_my/Applied-Deep-Learning-with-Keras/Lesson07/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataset  'test images'\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/bitai/proj_my/Applied-Deep-Learning-with-Keras/Lesson07/Datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_set  training_set\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/bitai/proj_my/Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats  dogs\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/bitai/proj_my/Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/training_set/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainSet = train_gen.flow_from_directory(\n",
    "    '/home/bitai/proj_my/Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/training_set/',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "testSet = test_gen.flow_from_directory(\n",
    "    '/home/bitai/proj_my/Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/test_set/',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 0.6932 - accuracy: 0.4936 - val_loss: 0.6931 - val_accuracy: 0.5069\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6932 - val_accuracy: 0.4812\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6931 - accuracy: 0.5066 - val_loss: 0.6931 - val_accuracy: 0.5038\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.5052 - val_loss: 0.6930 - val_accuracy: 0.5088\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5163\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.4848 - val_loss: 0.6931 - val_accuracy: 0.5169\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6932 - val_accuracy: 0.4938\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 0.6932 - accuracy: 0.4889 - val_loss: 0.6931 - val_accuracy: 0.5088\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6931 - accuracy: 0.5066 - val_loss: 0.6929 - val_accuracy: 0.5188\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6930 - val_accuracy: 0.5131\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6932 - val_accuracy: 0.4975\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6931 - accuracy: 0.5033 - val_loss: 0.6930 - val_accuracy: 0.5094\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6932 - accuracy: 0.5033 - val_loss: 0.6932 - val_accuracy: 0.4963\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6932 - accuracy: 0.4852 - val_loss: 0.6931 - val_accuracy: 0.5069\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6932 - val_accuracy: 0.4981\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6931 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5056\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5050\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6932 - val_accuracy: 0.4969\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6932 - val_accuracy: 0.4881\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6931 - accuracy: 0.5025 - val_loss: 0.6936 - val_accuracy: 0.4831\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.6931 - accuracy: 0.5052 - val_loss: 0.6930 - val_accuracy: 0.5094\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6933 - accuracy: 0.4939 - val_loss: 0.6933 - val_accuracy: 0.4881\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6931 - val_accuracy: 0.5094\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6932 - val_accuracy: 0.4919\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5031\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6931 - val_accuracy: 0.5050\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5188\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5125\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6931 - val_accuracy: 0.5038\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5125\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6932 - val_accuracy: 0.4981\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6931 - accuracy: 0.5045 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5006\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 27s 136ms/step - loss: 0.6931 - accuracy: 0.5091 - val_loss: 0.6934 - val_accuracy: 0.4894\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.4938\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6934 - val_accuracy: 0.4906\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6931 - accuracy: 0.5078 - val_loss: 0.6934 - val_accuracy: 0.4888\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6933 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5038\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6932 - val_accuracy: 0.4900\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.4969\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.5027 - val_loss: 0.6932 - val_accuracy: 0.4850\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.5050\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.4870 - val_loss: 0.6932 - val_accuracy: 0.4919\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.4988\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 26s 132ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5063\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5100\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5069\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6933 - val_accuracy: 0.4863\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6931 - val_accuracy: 0.5069\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5150\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 0.6932 - accuracy: 0.5050 - val_loss: 0.6932 - val_accuracy: 0.4975\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6932 - val_accuracy: 0.4869\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6932 - val_accuracy: 0.4975\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5088\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6931 - accuracy: 0.5092 - val_loss: 0.6932 - val_accuracy: 0.4963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.4994\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.5034 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6932 - val_accuracy: 0.4800\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5106\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6931 - accuracy: 0.5041 - val_loss: 0.6932 - val_accuracy: 0.4975\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6931 - accuracy: 0.5034 - val_loss: 0.6933 - val_accuracy: 0.4869\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.5022 - val_loss: 0.6931 - val_accuracy: 0.5025\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6931 - accuracy: 0.5019 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5063\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6933 - accuracy: 0.4948 - val_loss: 0.6931 - val_accuracy: 0.5113\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6932 - val_accuracy: 0.4925\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6932 - accuracy: 0.4919 - val_loss: 0.6932 - val_accuracy: 0.4944\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4988\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6931 - accuracy: 0.5061 - val_loss: 0.6931 - val_accuracy: 0.5019\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6932 - val_accuracy: 0.4900\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6932 - accuracy: 0.4878 - val_loss: 0.6932 - val_accuracy: 0.4931\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6931 - val_accuracy: 0.5069\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5050\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5031\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6931 - accuracy: 0.5042 - val_loss: 0.6930 - val_accuracy: 0.5094\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5088\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6932 - accuracy: 0.4880 - val_loss: 0.6931 - val_accuracy: 0.5013\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5006\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.4925\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5025\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 28s 138ms/step - loss: 0.6930 - accuracy: 0.5086 - val_loss: 0.6932 - val_accuracy: 0.4994\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 0.6932 - accuracy: 0.4895 - val_loss: 0.6931 - val_accuracy: 0.5013\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.4906\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.4950\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6932 - val_accuracy: 0.4850\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6931 - val_accuracy: 0.5025\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6932 - accuracy: 0.4795 - val_loss: 0.6932 - val_accuracy: 0.4988\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6932 - val_accuracy: 0.4850\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6932 - val_accuracy: 0.4950\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5106\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6932 - val_accuracy: 0.4975\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6932 - val_accuracy: 0.4719\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5025\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5175\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5013\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5119\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6931 - val_accuracy: 0.5031\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6932 - val_accuracy: 0.4969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5f7c77d3d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "classifier.fit_generator(\n",
    "    trainSet,\n",
    "    steps_per_epoch = int(10000/batch_size),\n",
    "    epochs = 100,\n",
    "    validation_data = testSet,\n",
    "    validation_steps = int(2500/batch_size)\n",
    ")\n",
    "\n",
    "# 엘프이프? 미분방정식 알아야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교재는 cpu 베이스의 코드라서 쓸 수가 없음\n",
    "# gpu 베이스로 코딩을 해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = image.load_img(\n",
    "    'test_image_2.jpg',\n",
    "    target_size = (64, 64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = image.img_to_array(new_image)\n",
    "new_image = np.expand_dims(new_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(new_image)\n",
    "# trainSet.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'Dog'\n",
    "else:\n",
    "    prediction = 'Cat'\n",
    "    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
