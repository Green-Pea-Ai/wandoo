{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6\r\n"
     ]
    }
   ],
   "source": [
    "# Use System Command\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential Module\n",
    "# scikit-learn, numpy, scipy, matplotlib pandas jupyter 한꺼번에 설치?\n",
    "# pip install scikit-learn numpy scipy matplotlib pandas jupyter\n",
    "\n",
    "# https://github.com/TrainingByPackt/Applied-Deep-Learning-with-Keras\n",
    "# git clone https://github.com/TrainingByPackt/Applied-Deep-Learning-with-Keras.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://sketch2code.azurewebsites.net/\n",
    "# Random Data to Mathematics Function(A.I)\n",
    "# Image(Input) -> A.I -> (Cat | Dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'data/bank.csv' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# You can't see the data\n",
    "!head data/bank.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'Applied-Deep-Learning-with-Keras/Lesson01/data/bank.csv' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# Now you can see it!\n",
    "# head command supports to see 10 data.\n",
    "# 앞의 10개의 데이터를 보여준다.\n",
    "!head Applied-Deep-Learning-with-Keras/Lesson01/data/bank.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File Applied-Deep-Learning-with-Keras/Lesson01/data/bank.csv does not exist: 'Applied-Deep-Learning-with-Keras/Lesson01/data/bank.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b18c0852c6f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m bank_data = pd.read_csv(\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m'Applied-Deep-Learning-with-Keras/Lesson01/data/bank.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m';'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File Applied-Deep-Learning-with-Keras/Lesson01/data/bank.csv does not exist: 'Applied-Deep-Learning-with-Keras/Lesson01/data/bank.csv'"
     ]
    }
   ],
   "source": [
    "# 중매업체도 이런 데이터를 활용한다고 함\n",
    "# pandas를 이용한 데이터 대입 과정?\n",
    "\n",
    "# 37페이지 노트내용 중요\n",
    "# 판다스에서 데이터프레임을 저장할 때 디폴트로 인덱스 열을 첫 번째 열에 넣는다.\n",
    "# 이 열을 명시하지 않으면 아무데나 추가하기 때문에 불편함을 발생시킬 수 있다.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "bank_data = pd.read_csv(\n",
    "    'Applied-Deep-Learning-with-Keras/Lesson01/data/bank.csv', \n",
    "    sep = ';'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행과 열의 정보를 알 수 있다.\n",
    "# row 4521\n",
    "# col 17\n",
    "bank_data.shape\n",
    "\n",
    "# 1장 다 끝내고 J9?은 결원으로 내일하신다고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 열 성분중 y에 해당하는 것을 밀어버림\n",
    "feats = bank_data.drop('y', axis=1)\n",
    "# 열 성분중 y에 해당하는 성분만 내포시킴\n",
    "target = bank_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape[0]은 행을 나타내고 shape[1]은 열을 나타낸다.\n",
    "print(f'Features table has {feats.shape[0]} rows and {feats.shape[1]} columns')\n",
    "print(f'Taget Table has {target.shape[0]} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀한 데이터프레임 CSV 파일로 저장하기\n",
    "feats.to_csv('data/bank_data_feats.csv')\n",
    "target.to_csv('data/bank_data_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header='y'는 저장 정보가 y정보임을 알려주는데\n",
    "# 현재 케이스에서는 이것이 없어도 정보 저장이 잘 되었다.\n",
    "# 누락이 된 경우 확인이 어려울 수 있으니 적절한 조치가 필요\n",
    "# 욜로 2는 라벨이 20개, 최신버전은 80개?\n",
    "target.to_csv('data/bank_data_target2.csv', header = 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리란 무엇인가?\n",
    "# 데이터를 분석하게되면\n",
    "# 심한 경우 하루 ~ 삼일이 걸릴 수 있다.\n",
    "# 안그래도 느린데 느린 문자열 방식을 사용하면 더 느려질 것이다.\n",
    "# 문자열이면 배열에 저장해도 인덱싱하기 힘들다\n",
    "# 그러나 숫자 방식을 사용하면 배열에 인덱싱도 용이하다.\n",
    "# 그러므로 인코딩을 해서 특정 데이터를 숫자화 하면 더 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe()는 수치화 할 수 있는 정보들에\n",
    "# 대한 개수, 평균(mean), 표준편차, 4분위수, 최소값, 최대값 등을 계산한다.\n",
    "res = bank_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count는 전체 개수\n",
    "# mean은 평균\n",
    "# std는 표준편차\n",
    "# min은 최소값\n",
    "# max는 최대값\n",
    "# 25%, 50%, 75%는 사분위수\n",
    "# 데이터를 4등분하므로 사이에는 3개가 있다.(0, 25, 50, 75, 100?)\n",
    "# 그러므로 사분위수에서는 데이터 3개가 나온다.\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'default' 열이 가지고 있는 데이터의 정보를 수치화한다.\n",
    "bank_data['default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(kind='bar')를 통해서 막대 그래프를 그릴 수 있다.\n",
    "bank_data['default'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data['is_default'] = bank_data['default'].apply(\n",
    "    lambda row: 1 if row == 'yes' else 0\n",
    ")\n",
    "\n",
    "bank_data['is_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data[['default', 'is_default']].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data['is_loan'] = bank_data['loan'].apply(\n",
    "    lambda row: 1 if row == 'yes' else 0\n",
    ")\n",
    "\n",
    "# bank_data['is_loan']\n",
    "bank_data[['loan', 'is_loan']].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미국 데이터라고 함\n",
    "bank_data['is_housing'] = bank_data['housing'].apply(\n",
    "    lambda row: 1 if row == 'yes' else 0\n",
    ")\n",
    "\n",
    "# bank_data['is_loan']\n",
    "bank_data[['housing', 'is_housing']].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummies의 기능 설명\n",
    "# DataFrame : 엑셀의 시트 하나하나?\n",
    "# 엑셀 형식으로 리스트화 할 수 있는 정보들을 테이블로 만든다.\n",
    "# 수치화할 수 있어야만 이것이 가능하다.\n",
    "\n",
    "# nan은 not a number(숫자가 아니므로 제외됨)\n",
    "# get_dummies()의 인자 dummy_na=True로 설정하면 \n",
    "# Not a Number에 대해서도 처리를 하게 된다.\n",
    "help(pd.get_dummies)\n",
    "\n",
    "# 센서들은 데이터 처리를 하려면 미분을 해야함\n",
    "# NaN 데이터를 무시할 수 있어야 자율주행 자동차의 사고를 방지할 수 있다.\n",
    "# 필요한 정보만 받아들여서 동작에 반영함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data['marital'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bank_data['marital'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 힘들게 lambda 써서 복잡하게 했는데\n",
    "# pd.get_dummies 한 방으로 모든것이 끝났다.\n",
    "marital_dummies = pd.get_dummies(bank_data['marital'])\n",
    "\n",
    "marital_dummies.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이혼한 사람 데이터에서 날리기\n",
    "\n",
    "# get_dummies()로 얻은 결과도 여전히 drop()을 통해서\n",
    "# 정보 자체를 배제할 수 있다.\n",
    "\n",
    "# 이혼하면 중매업체에서 점수가 많이 까임\n",
    "# 영세 업체에서는 이혼한 사람은 데이터에서 날린다?\n",
    "marital_dummies.drop('divorced', axis = 1, inplace=True)\n",
    "marital_dummies.columns = [\n",
    "    f'marital_{colname}'                           \n",
    "    for colname in marital_dummies.columns\n",
    "]\n",
    "marital_dummies.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data = pd.concat(\n",
    "    [bank_data, marital_dummies], axis=1\n",
    ")\n",
    "\n",
    "bank_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결혼한 사람의 집 보유 비중이 높은 점과 같은 정보를 얻을 수 있다.\n",
    "bank_data.drop('marital', axis=1, inplace=True)\n",
    "\n",
    "bank_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도전! education 열 날리고 더미행(인코딩 정보 - 0,1) 삽입하기\n",
    "\n",
    "# 저장은 to.csv로 하기 때문에 열 날린거 살리고 싶으면\n",
    "# 위에 원본 코드를 다시 실행하고 다시 작업한다.(pd.read_csv ~~~)\n",
    "education_dummies = pd.get_dummies(bank_data['education'])\n",
    "\n",
    "# education_dummies\n",
    "bank_data = pd.concat([bank_data, education_dummies], axis=1)\n",
    "bank_data.drop('education', axis=1, inplace=True)\n",
    "\n",
    "bank_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도전! 강사님 풀이 1\n",
    "education_dummies = pd.get_dummies(\n",
    "    bank_data['education']\n",
    ")\n",
    "\n",
    "education_dummies.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 도전! 강사님 풀이 2\n",
    "education_dummies.columns = [\n",
    "    f'education_{colname}'\n",
    "    for colname in education_dummies.columns\n",
    "]\n",
    "education_dummies.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도전! 강사님 풀이 3\n",
    "bank_data = pd.concat(\n",
    "    [bank_data, education_dummies], axis=1\n",
    ")\n",
    "bank_data.drop('education', axis=1, inplace=True)\n",
    "bank_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_map = {\n",
    "    'jan' : 1, 'feb' : 2,  'mar' : 3,  'apr' : 4,\n",
    "    'may' : 5, 'jun' : 6,  'jul' : 7,  'aug' : 8,\n",
    "    'sep' : 9, 'oct' : 10, 'nov' : 11, 'dec' : 12\n",
    "}\n",
    "bank_data['month'] = bank_data['month'].map(month_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 46p 그림 1.19처럼 object가 없어야 정리가 잘 된 것이다.(숫자로 인코딩 처리 완료?)\n",
    "# object가 남아있는 이유? 인코딩이 완료가 안돼서\n",
    "# 컴퓨터가 데이터를 학습하게 만들려면 적절한 인코딩을 적용해서\n",
    "# 컴퓨터가 사용할 수 있게 만들어야 한다.\n",
    "\n",
    "# 저자는 알아서 인코딩하라고 던져줌\n",
    "bank_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data = pd.read_csv(\n",
    "    'Applied-Deep-Learning-with-Keras/Lesson01/data/bank_data_feats_e2.csv',\n",
    "    index_col = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data['was_contacted'] = bank_data['pdays'].apply(\n",
    "    lambda row: 0 if row == -1 else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data('was_contacted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홍보했을 때 안했을 때 구매율 등으로 응용해서 사용해볼 수 있다.\n",
    "bank_data.drop('pdays', axis=1, inplace=True)\n",
    "bank_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참 긍정   - 예측이 긍정, 현실도 긍정 (적이 있다)\n",
    "# 거짓 긍정 - 예측이 긍정, 현실은 부정 (아무데나 공격함)\n",
    "# 거짓 부정 - 예측이 부정, 현실은 긍정 (적한테 공격당함)\n",
    "# 참 부정   - 예측이 부정, 현실도 부정 (적이 없다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = pd.read_csv(\n",
    "    'Applied-Deep-Learning-with-Keras/Lesson01/data/bank_data_feats_e2.csv',\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "target = pd.read_csv(\n",
    "    'Applied-Deep-Learning-with-Keras/Lesson01/data/bank_data_target_e2.csv',\n",
    "    index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "# y = Mx + b\n",
    "# 학습시킬 정보, 테스트할 정보를 적절하게 만든다.\n",
    "# test_size 학습에 적응하는 비율을 결정한다.\n",
    "# test_size = 0.2\n",
    "# 학습에 80% 데이터 활용\n",
    "# 테스트에 20% 데이터 활용\n",
    "# 테스트 사이즈를 적정한 수치로 줘야 딥러닝하다가 뇌절하지 않는다.\n",
    "# random_state : 재현율(나쁘지 않은 수준임)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feats, target,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size와 random_state로 생성된 정보\n",
    "# 테스트인 905가 0.2 사용한 값\n",
    "# 학습값은 3616 0.8 사용한 값(테스트 값의 약 4배)\n",
    "# 열은 데이터 프레임에서 주어진 열의 개수\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# y = 1 / (1 + e^-x)\n",
    "model = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = Mx + b 형태를 맞추는 작업\n",
    "# (80% 정보만으로 맞춤 20%의 부족분으로 인해 문제 발생할 수도 있다)\n",
    "# 20%로 4번 학습하는 모델도 있다.\n",
    "model.fit(X_train, y_train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터를 통해 예측을 수행한다.\n",
    "# 코드 한줄씩 실행해보기\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# 앞서 구한 예측값(y_pred)와\n",
    "# 실제 테스트 데이터인(y_test)를 가지고\n",
    "# 정확성에 대해 계산하는 작업\n",
    "accuracy = metrics.accuracy_score(\n",
    "    y_pred = y_pred, y_true = y_test\n",
    ")\n",
    "print(f'Accuracy of the model is {accuracy * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, _ = \\\n",
    "    metrics.precision_recall_fscore_support(\n",
    "        y_pred=y_pred, y_true=y_test,\n",
    "        average='binary'\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f'Precision: {precision:.4f}\\n' + \n",
    "    f'Recall: {recall:.4f}\\n' +\n",
    "    f'score:{fscore:.4f}'\n",
    ")\n",
    "# 정확도 88%로 상당히 높다.\n",
    "# 그러나 정밀도와 재현율이 낮으며\n",
    "# 종합점수인 F1 점수가 굉장히 낮다.\n",
    "# 그러므로 해당 모델을 Accuracy만 높다고\n",
    "# 일반적인 상황에 일괄적으로 적용하면 망한다.\n",
    "# 책을 따라가다보면 아래 수치를 높일 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef :a와 b의 계수 ~~~\n",
    "# 대출에 영향을 주는 요소들\n",
    "coef_list = [f'{feature}: {coef}'\n",
    "    for coef, feature in sorted(\n",
    "        zip(\n",
    "            model.coef_[0],\n",
    "            X_train.columns.values.tolist()\n",
    "        )\n",
    "    )]\n",
    "\n",
    "for item in coef_list:\n",
    "    print(item)\n",
    "    \n",
    "# 돈있는 사람은 대출 안받고 돈없는 사람은 대출을 받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\n",
    "    'Applied-Deep-Learning-with-Keras/Lesson01/data/bank_data_target_e2.csv',\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "target['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['y'].value_counts() / target.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# [0] ~ [4520] 까지 4521개를 만들어라.\n",
    "y_baseline = pd.Series(data=[0] * target.shape[0])\n",
    "\n",
    "y_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_baseline2 = pd.Series(data=target.shape[0])\n",
    "\n",
    "y_baseline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, _ = \\\n",
    "    metrics.precision_recall_fscore_support(\n",
    "        y_pred=y_baseline, y_true=target['y'],\n",
    "        average='macro'\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f'Precision: {precision:.4f}\\n' + \n",
    "    f'Recall: {recall:.4f}\\n' +\n",
    "    f'score:{fscore:.4f}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
